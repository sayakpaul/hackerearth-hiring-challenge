{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a1a8e0b9d755365675f613ae4c1bcd549c45f0ce"
   },
   "outputs": [],
   "source": [
    "!pip install fastai==0.7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4cda15ce3386f0fef518c589428bf38ce0148f96"
   },
   "source": [
    "**Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from fastai.imports import *\n",
    "from fastai.structured import *\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "de3f168445264e3db305e57f86f66b3638ec850c"
   },
   "source": [
    "Load the training and testing sets. Parse the date columns as `date` by explicitly specifying it. This speeds up the loading process in general as the csv_reader does not have to spend time in deriving the `dtypes` of  these columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../input/train_file.csv',parse_dates=[\"Application Date\", \"Issue Date\", \"Final Date\", \"Expiration Date\"])\n",
    "test_df = pd.read_csv('../input/test_file.csv', parse_dates=[\"Application Date\", \"Issue Date\", \"Final Date\", \"Expiration Date\"])\n",
    "\n",
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4e550c00522b16eb8e0b6e84d502182a06020625"
   },
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "19a2d9528f2d3dfe83163fb8f8e6ccec7015a5a3"
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a8321f5f9c7a5421317c2257a5fb8c3e6e35f858"
   },
   "outputs": [],
   "source": [
    "train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "abd74d9c047ad6899f6b88851bfef7a380ef5600"
   },
   "outputs": [],
   "source": [
    "test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7a229902abf928575dcdf4737e72eaf55d6bf6ba"
   },
   "source": [
    "**Lots of missing values!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b2ecd11e688a8644d0c38a965dd0c346db0f2064"
   },
   "source": [
    "Let's now see the target distribution of the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6fbd5218138dbdb6676b75b6cbfd0aea0b50a737"
   },
   "outputs": [],
   "source": [
    "label_counts = Counter(train_df['Category'].values)\n",
    "label_counts.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "36b944833240f0447037424e1195f204b0393ca8"
   },
   "source": [
    "* **Start of feature engineering**:\n",
    "    Merge the training set and testing set and merging do not shuffle the instances randomly. This will help in two ways - \n",
    "    * Generate new features (when performing one-hot encoding for preprocessing categorical features) thereby allowing an ML   model to train with low bias.\n",
    "    * Reduces the chance of data leakages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a1eb22ca23e10a8b6366627cb77cd62963fcaa41"
   },
   "outputs": [],
   "source": [
    "test_df['Category'] = '' # So that there is not mismatch in the dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2332d0349e4d4c1d139641ea690b0fe6d7f5c21b"
   },
   "outputs": [],
   "source": [
    "all_data_df =pd.concat([train_df,test_df])\n",
    "all_data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "80d481959a2ed4e3b52826455b91fd2bb20dbb2b"
   },
   "source": [
    "Both the datasets have the following date columns -\n",
    "* Application Date\n",
    "* Issue Date\n",
    "* Final Date\n",
    "* Expiration Date\n",
    "\n",
    "The **fast.ai** function `add_datepart()` helps in a lot of ways. \n",
    "\n",
    "> The following method extracts particular date fields from a complete datetime for the purpose of constructing categoricals. You should always consider this feature extraction step when working with date-time. Without expanding your date-time into these additional fields, you can't capture any trend/cyclical behavior as a function of time at any of these granularities. - [Fast.AI's course on Machine Learning for coders](https://github.com/fastai/fastai/blob/master/courses/ml1/lesson1-rf.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "96ff278645a716dd64c5d4af488d4ed196e3f90e"
   },
   "outputs": [],
   "source": [
    "add_datepart(all_data_df,'Application Date')\n",
    "add_datepart(all_data_df,'Issue Date')\n",
    "add_datepart(all_data_df,'Final Date')\n",
    "add_datepart(all_data_df,'Expiration Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7866a387e62ab10d469c7e76bbc98708f77fedab"
   },
   "outputs": [],
   "source": [
    "all_data_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "94f243fb45d81e52b3906ad7915d319106e16898"
   },
   "source": [
    "Another **fast.ai** function - `train_cats()`, which allows to convert strings to `pandas` categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b1f818d0c8057d6757dd1241b605b4d044398a84"
   },
   "outputs": [],
   "source": [
    "train_cats(all_data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "58aa67170fea2923fd1554c93131f1d79427d8bb"
   },
   "outputs": [],
   "source": [
    "all_data_df.Category.cat.categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "14ccc8a345cf0559a085c11202d12e16da61f8da"
   },
   "source": [
    "**Missing values' handling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cb11b3181960f1723d4cbb4b8bc38c2f61a5a468"
   },
   "outputs": [],
   "source": [
    "df_x, df_y, nas = proc_df(all_data_df, 'Category')\n",
    "df_x.shape, df_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4698ca05f560fa51f817a6a150ea8c6f3d14ff31"
   },
   "outputs": [],
   "source": [
    "label_counts = Counter(df_y)\n",
    "label_counts.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7347e19834418dd7898b01f52c5e19fcab7bca9d"
   },
   "source": [
    "The 0 category samples belong to the testing set. Apart from that all the target distributions are  same. Encoding mappings are as follows - \n",
    "- 5 -> SINGLE FAMILY / DUPLEX\n",
    "- 4 -> MULTIFAMILY\n",
    "- 3 -> INSTITUTIONAL\n",
    "- 2 -> INDUSTRIAL\n",
    "- 1 -> COMMERCIAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4fee70bab8587e0fa39fdd9a1c297c995ac1302f"
   },
   "source": [
    "We are done with the feature engineering part for now. We can get back to the initial train:test ration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "42c654e41f87f6e06f8c75e7cce632590dd60518"
   },
   "outputs": [],
   "source": [
    "def split_vals(a,n): return a[:n], a[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8bd7d9437ab8b2a4a887b1023f911a3047824886"
   },
   "outputs": [],
   "source": [
    "df_train, test  = split_vals(df_x,33539)\n",
    "y_train,_ = split_vals(df_y,33539)\n",
    "df_train.shape, y_train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aa409d82a952c97b36a5f91b2c6c5cd37df9f0e2"
   },
   "source": [
    "An additional split of training and validation sets from the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "34037ce5f67b4590cd6e473be002bbef23d75f89"
   },
   "outputs": [],
   "source": [
    "X_train, X_valid = split_vals(df_train,28539)\n",
    "y_train, y_valid = split_vals(y_train,28539)\n",
    "\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cddac35152c23b0b6648c6cf266de4e2e42ca695"
   },
   "source": [
    "Given a shorter time-frame, trying out different ML models can be tedious. H2O.ai's AutoML framework is pretty good for situations like this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "fd120a4804b48024b8f4b71065f6786d639b23fb"
   },
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "h2o.init(max_mem_size='10G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "507a5e6f91ea1e026949eaa676316b586e70820f"
   },
   "outputs": [],
   "source": [
    "X_train['Category'] = y_train\n",
    "X_valid['Category'] = y_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d08f6c6935e29301c2a73131f39a1836e0ce777b"
   },
   "source": [
    "All H2O models require the data to be presented in a format called [H2OFrame](http://docs.h2o.ai/h2o/latest-stable/h2o-py/docs/frame.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "262f1d23602a33c4d448bd2c855580d5d97630ea"
   },
   "outputs": [],
   "source": [
    "X_train_h2o = h2o.H2OFrame(X_train)\n",
    "X_valid_h2o = h2o.H2OFrame(X_valid)\n",
    "X_test_h2o = h2o.H2OFrame(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1b7a85e42d937af91420c380fa3af25d8b2c8a94"
   },
   "source": [
    "We have a multi-class/multi-nomial classification problem here. And H2O requires the target columns (for classification problems) to be in `factors`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ae486bd0a9595f57c96f4cde117201f80935b078"
   },
   "outputs": [],
   "source": [
    "X_train_h2o['Category'] = X_train_h2o['Category'].asfactor()\n",
    "X_valid_h2o['Category'] = X_valid_h2o['Category'].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e97efe39a04282f6fc20dff0c96a2493d49d35ed"
   },
   "outputs": [],
   "source": [
    "predictors = X_train_h2o.columns[0:-1]\n",
    "target = 'Category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "12f741ac36a0b2b41097cc897425b99ce785d0ef"
   },
   "outputs": [],
   "source": [
    "auto_h2o = H2OAutoML(seed = 1, sort_metric = 'mean_per_class_error')\n",
    "%time auto_h2o.train(x=predictors,\\\n",
    "               y=target,\\\n",
    "               training_frame=X_train_h2o)\n",
    "\n",
    "lb = auto_h2o.leaderboard\n",
    "lb.head(rows=lb.nrows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e97536a4747eb1df8a00964508aa7d7711d59306"
   },
   "source": [
    "H2O's AutoML yielded a **Stacked Ensemble** model as the most superior model among few others. Let's take a look the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2bf586486bad1f1b6f41379c6aeaf2509534a369"
   },
   "outputs": [],
   "source": [
    "auto_h2o.leader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "940716078080c8f2d3ecc3ab11914587bca2a1a9"
   },
   "source": [
    "> So, the Stacked Ensemble consists of MultiNomial GLMs. Let's go ahead and see the confusion matrix of the model on the validation set. GLMs are generally good for datasets having high dimensionality and sparsity. This further confirms the hypothesis that H2O's AutoML picked up the right model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5f7b43fe6b2c84553b83cd69c628aed89233a7c6"
   },
   "outputs": [],
   "source": [
    "auto_h2o.leader.confusion_matrix(X_valid_h2o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3b5b6c1ad97821e3f4f0bfdf65d212a239dd45d4"
   },
   "source": [
    "<h3>**Interpretation:**</h3> \n",
    "![cm_interpretation](https://i.ibb.co/V2hNKfS/Capture.png)\n",
    "<center>[Source](http://docs.h2o.ai/h2o/latest-stable/h2o-docs/performance-and-prediction.html#f1)</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a8506bf91954c06328dd64c27c9f11bc2c8229a6"
   },
   "outputs": [],
   "source": [
    "label_counts = Counter(X_valid['Category'].values)\n",
    "label_counts.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "daa2d304033371c41c722c45086c53a5de189864"
   },
   "source": [
    "The model performs fairly good for the classes 5 and 1. But the model performs not so well for classes - 4, 3 and 2 (encoded version of the original categories). This is happening because of the poor sample distributions in the training and validation set. As a result, the Stacked Ensemble model is failing to capture the trends underlying the sample belonging to these three classes. May be a better split in the training and validation set would result in a better model. As a next step, we can come up with better split between the training and validation sets so as to better distribute the samples belonging to class 4, 3 and 2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a8b55281cba3390e712b2041427aaa7b59ad0440"
   },
   "source": [
    "**Make prediction on the testing set and prepare the submission file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9613c476e687e38327b2c7319037b5303ba08d46"
   },
   "outputs": [],
   "source": [
    "test_preds = auto_h2o.leader.predict(X_test_h2o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7b01d640ad94a8f541a278531cab0e687903a8c3"
   },
   "outputs": [],
   "source": [
    "application_numbers = test_df['Application/Permit Number']\n",
    "results=(h2o.as_list(test_preds['predict'])).iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "57377edb57135a4dbbc0232d2da21b3f77837e63"
   },
   "outputs": [],
   "source": [
    "final=pd.concat([application_numbers, results], axis=1)\n",
    "final.rename(columns={'predict': 'Category'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b660a3c493774ddb79856d58de50d81343427534"
   },
   "source": [
    "- 5 -> SINGLE FAMILY / DUPLEX\n",
    "- 4 -> MULTIFAMILY\n",
    "- 3 -> INSTITUTIONAL\n",
    "- 2 -> INDUSTRIAL\n",
    "- 1 -> COMMERCIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "60420127618e767f97ff730411cc7b73e209dbe9"
   },
   "outputs": [],
   "source": [
    "final.loc[final['Category'] == 5, 'Category'] = 'SINGLE FAMILY / DUPLEX'\n",
    "final.loc[final['Category'] == 4, 'Category'] = 'MULTIFAMILY'\n",
    "final.loc[final['Category'] == 3, 'Category'] = 'INSTITUTIONAL'\n",
    "final.loc[final['Category'] == 2, 'Category'] = 'INDUSTRIAL'\n",
    "final.loc[final['Category'] == 1, 'Category'] = 'COMMERCIAL'\n",
    "\n",
    "print (final.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "665a1ead69b9b3d38b8827fc9369170cd1c2a469"
   },
   "outputs": [],
   "source": [
    "final.to_csv('submission.csv', sep=',',index=False) \n",
    "!head -5 submission.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "13d5df7be336d124568a86aa00449471c2ded3fc"
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
